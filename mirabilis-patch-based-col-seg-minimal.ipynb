{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Defining the model training function:\nTo train the model we will need a directory of patches for training and a directory of patches for validation. These should have been generated from separate images (validation patches should not come from the same image as a training patch). Within each directory there should be positive (with colony) and negative (agar/background only) directories.","metadata":{}},{"cell_type":"code","source":"train_data_dir = './patches/train'\nval_data_dir = './patches/val'\n\ndef train_model(model, X_train_imgs, batch_size=32, epochs=50, augmented=True, reweight_classes=False):\n\n  model.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n    loss = 'binary_crossentropy',\n    metrics=['accuracy']\n  )\n  print('compiled')\n  datagen_args = {}\n  if augmented:\n\n    datagen_args = {\n        # Could augment by flipping horizontally & changing brightness, but that reduces performance\n#         'rotation_range': 10,\n#         'horizontal_flip': True,\n#         'brightness_range': [0.5, 1.5],\n        'rescale':1. / 255,\n        'featurewise_center': True\n    }\n  else:\n    datagen_args = {'rescale':1. / 255,\n        'featurewise_center': True}\n    \n    \n  # Let's define our generators etc\n  train_datagen = ImageDataGenerator(**datagen_args)\n  val_datagen = ImageDataGenerator(**datagen_args)\n\n  # Fit the generators\n  train_datagen.fit(X_train_imgs)\n  val_datagen.fit(X_train_imgs)\n  \n\n  train_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(DEFAULT_IMG_SIZE, DEFAULT_IMG_SIZE),\n    color_mode = 'grayscale',\n    batch_size=batch_size,\n    class_mode = 'binary')\n\n  val_generator = val_datagen.flow_from_directory(\n    val_data_dir,\n    target_size=(DEFAULT_IMG_SIZE, DEFAULT_IMG_SIZE),\n    color_mode = 'grayscale',\n    batch_size=batch_size,\n    class_mode = 'binary')\n    \n  fit_generator_args = {}\n  if reweight_classes:\n    fit_generator_args = {\n        'class_weight': class_weights_dict\n    }\n    \n\n  callback = tf.keras.callbacks.EarlyStopping(\n      monitor='val_loss', patience=3, restore_best_weights=True)\n    \n  # fits the model on batches with real-time data augmentation:\n  history = model.fit_generator(\n    train_generator,\n    steps_per_epoch=num_train_patches / batch_size,\n    epochs=epochs,\n    validation_data =  val_generator,\n    callbacks = [callback],\n    **fit_generator_args \n  )\n\n  return history, train_datagen","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prepare a sample of the data for standardization-load in however many patches the model mean will be fit on (for featurewise_center) and convert to tensors","metadata":{}},{"cell_type":"code","source":"train_patch_sample = []\ncount = 0\nfor path in train_image_paths:\n    test_patch = plt.imread(path)\n    test_patch = np.array(test_patch)\n    test_patch = tf.expand_dims(test_patch, 2)\n    train_patch_sample.append(test_patch)\n    count += 1\n    if count >= 10000:\n        break\n\ntrain_patch_sample_2 = tf.convert_to_tensor(train_patch_sample)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generate a 'class_weights_dict' from sklearn.utils","metadata":{}},{"cell_type":"code","source":"# Define the model\ncnn_model_5 = models.Sequential([\n  layers.Conv2D(16, (3, 3), \n                kernel_regularizer=tf.keras.regularizers.l2(0.01), \n                bias_regularizer=tf.keras.regularizers.l2(0.01), \n                input_shape=(DEFAULT_IMG_SIZE, DEFAULT_IMG_SIZE, 1)),\n  layers.LeakyReLU(),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, (3, 3), activation='relu',\n               kernel_regularizer=tf.keras.regularizers.l2(0.01), \n                bias_regularizer=tf.keras.regularizers.l2(0.01),), \n  layers.MaxPooling2D((2, 2)),\n  layers.Dropout(rate=0.2),\n  layers.Flatten(),\n  layers.Dropout(rate=0.2),\n  layers.Dense(32, activation='relu',),\n  layers.Dense(1, activation='sigmoid',)\n  \n])\nprint(cnn_model_5.summary())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train the model:","metadata":{}},{"cell_type":"code","source":"[histories_cnn_5, cnn_5_train_datagen] = train_model(cnn_model_5, train_patch_sample_2, batch_size=16, epochs=15, augmented=False, reweight_classes=True)","metadata":{},"execution_count":null,"outputs":[]}]}